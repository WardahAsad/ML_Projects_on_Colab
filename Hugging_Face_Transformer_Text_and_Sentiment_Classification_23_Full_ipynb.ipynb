{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WardahAsad/ML_Projects_on_Colab/blob/main/Hugging_Face_Transformer_Text_and_Sentiment_Classification_23_Full_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGmwLf9D-Us2"
      },
      "source": [
        "# ğŸ“˜ Assignment: Sentiment Classification with Hugging Face Transformers (SST-2 Dataset)\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ¯ Objective\n",
        "In this assignment, you will build a **Text Classification** model using **Hugging Face**'s `transformers` library. Specifically, you will work with the **SST-2 (Stanford Sentiment Treebank)** dataset to classify movie reviews as either positive or negative sentiments.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§© Assignment Tasks\n",
        "\n",
        "### âœ… Q1. Install and Import Libraries\n",
        "- Install the necessary libraries for this assignment:\n",
        "  - **Hugging Face**'s `transformers`\n",
        "  - **PyTorch** for model training\n",
        "  - **Scikit-learn** for data preprocessing and evaluation\n",
        "  - **Pandas** for data handling\n",
        "  - **Matplotlib/Seaborn** for visualizations\n",
        "- Import the libraries that are required to perform the tasks mentioned below.\n",
        "\n",
        "---\n",
        "\n",
        "### âœ… Q2. Load the Dataset\n",
        "- The dataset will be similar to the **SST-2** sentiment analysis dataset, containing two columns:\n",
        "  - **Sentence**: A text review of a movie.\n",
        "  - **Label**: The sentiment of the review, where `0` represents a negative sentiment and `1` represents a positive sentiment.\n",
        "- Load the dataset and inspect the first few rows to understand the structure of the data.\n",
        "\n",
        "---\n",
        "\n",
        "### âœ… Q3. Preprocess the Data\n",
        "- Perform preprocessing steps such as:\n",
        "  - **Cleaning the text**: Remove unnecessary punctuation or special characters.\n",
        "  - **Tokenization**: Tokenize the text using a pre-trained tokenizer from Hugging Face.\n",
        "- Split the dataset into:\n",
        "  - **80% training data**\n",
        "  - **20% validation data**\n",
        "- Ensure the labels are in numerical format (e.g., 0 and 1 for sentiment).\n",
        "\n",
        "---\n",
        "\n",
        "### âœ… Q4. Load Pre-trained Model and Tokenizer\n",
        "- Load a pre-trained transformer model such as **BERT** (`bert-base-uncased`) or **DistilBERT** (`distilbert-base-uncased`).\n",
        "- Load the corresponding tokenizer for the model.\n",
        "  \n",
        "---\n",
        "\n",
        "### âœ… Q5. Tokenize the Dataset\n",
        "- Use the tokenizer to encode the **Sentence** column into tokenized inputs that the model can understand.\n",
        "- Convert the tokenized data into tensors for training.\n",
        "\n",
        "---\n",
        "\n",
        "### âœ… Q6. Fine-Tune the Model\n",
        "- Fine-tune the pre-trained model on the sentiment classification task using cross-entropy loss.\n",
        "- Set up the optimizer (e.g., AdamW) and learning rate scheduler.\n",
        "- Train the model for a few epochs and monitor the training/validation loss during the process.\n",
        "\n",
        "---\n",
        "\n",
        "### âœ… Q7. Evaluate the Model\n",
        "- After fine-tuning, evaluate the model using the validation dataset.\n",
        "- Generate predictions for the validation set and compute the **accuracy**.\n",
        "- Use the `classification_report` from Scikit-learn to calculate additional evaluation metrics such as precision, recall, and F1-score.\n",
        "\n",
        "---\n",
        "\n",
        "### âœ… Q8. Visualize the Results\n",
        "- Plot the training and validation loss curves to visualize how the modelâ€™s loss decreased over time.\n",
        "- Plot a **confusion matrix** to evaluate how well the model is distinguishing between positive and negative reviews.\n",
        "\n",
        "---\n",
        "\n",
        "### âœ… Q9. Fine-Tuning and Hyperparameter Tuning\n",
        "- Experiment with different hyperparameters such as learning rate, batch size, and number of epochs.\n",
        "- Evaluate the impact of these changes on the modelâ€™s performance.\n",
        "\n",
        "---\n",
        "\n",
        "### âœ… Q10. Compare Different Models\n",
        "- Fine-tune and evaluate different transformer models (e.g., `distilbert-base-uncased`, `roberta-base`, etc.) and compare their performance on the SST-2 sentiment classification task.\n",
        "- Discuss which model performed best in terms of accuracy and speed, and explain why.\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… Submission Checklist\n",
        "Before submitting, make sure:\n",
        "- [ ] You have completed all tasks as described.\n",
        "- [ ] All code cells are executed and commented on.\n",
        "- [ ] All visualizations (plots, graphs, etc.) are labeled and explained.\n",
        "- [ ] The notebook runs from top to bottom without errors.\n",
        "- [ ] The file is named `yourname_sst2_sentiment_classification.ipynb`.\n",
        "\n",
        "---\n",
        "\n",
        "> ğŸ“© Submit your notebook in .ipynb\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”’ Solution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDLQtB8SVvK7",
        "outputId": "0ae206ca-c55e-4e2e-bc91-52e163098a39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "pip install transformers datasets torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "a0feaf3ff44d40b287fb028d220adfbd",
            "f68b1fd7402f401495a626f0e9426408",
            "1c5cd859792e4c24a443a085c3402740",
            "3a2aec20b83e4387a832f050a5ae600c",
            "28f898589a614296bffc97942718d6bf",
            "72a52a5a9062455285ebf86ecfa6cc0d",
            "a3241350ac524550a6342da4699eef7d",
            "e209c062eb1d415ab1a465959862d6cf",
            "04f307cde55342e099bd4de7bddbb557",
            "64b06386a2bb4046afdabe3efe826938",
            "2ca01908cfbb4324a911caeb87d3df0b",
            "067d72b8351c4ab381edbc22657e0bbf",
            "1db436dae14d439e89067ef33a7a5044",
            "fedf8ea9c3ba4c9580ad4c6996f313cf",
            "ec286c17d5c944b99d8008bcf9b7a334",
            "6d286e6069734641a99e6acf95a505eb",
            "dac64bd482d743b9bdbb1fd15f294570",
            "14d25e72f3354416a5fb770ff01f8be4",
            "4b9862858a834b2598c4bb129f7118cb",
            "1f099200987a49b58953322e0f222dcc"
          ]
        },
        "id": "VpcimQg0jJ8I",
        "outputId": "f95b08a1-a4ab-4a2f-ebcd-ffba38028c77"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a0feaf3ff44d40b287fb028d220adfbd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Setting Hugging Face Access Token in Colab\n",
        "from huggingface_hub import login\n",
        "import os\n",
        "\n",
        "hf_token = os.environ.get(\"HF_TOKEN\")\n",
        "login(token=hf_token)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6UXxMeZXJWa"
      },
      "outputs": [],
      "source": [
        "# Q1. Install and Import Libraries\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHOkpCHlXbKk"
      },
      "outputs": [],
      "source": [
        "# i will import these later in the relevant cell where i need these libraries\n",
        "# from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "0e61f896cb73452cb09fe3f3bff85fc8",
            "3586a43f63d244c98624dd42d5da3a5f",
            "4f4c18fe2530412ab6e8d0677977392c",
            "348c4666559a4f6d9e045b85bce3fa56",
            "826cc80060c44d779f0c46388dd0be4f",
            "48191eeab8074f9183b3fc4512fac825",
            "6e8edf2a14ee40cebcba7a8f463624f0",
            "526f6059a6fd451e946317d41eeea51b",
            "44d3967d16a143d68e0774ba78da6f9c",
            "8680e414ccb0427b966b7252db0a178a",
            "6a2275ecd117442482931602ce3e6821",
            "f14879c9a05f424d9c9ef2d6c389e28d",
            "e966d7f6ad2b4b0aacd05f07fbf254b3",
            "b79ca14de0474258bbbd4e5d61fefbc3",
            "48aa0e3318c84d6b9af5f83ab5d4011e",
            "a13718c231944712acb1141b94fa7028",
            "1f4681c04b474e49a79dc93f23798863",
            "69384ebf1aea46429f77e3d1a7dd3fe2",
            "0be1a7b2ca0c4e4cb616560d3f5b8f82",
            "42e636a94b3748518f4942326d50288c",
            "3f6478bd04ce4b9b94c381355d229f75",
            "df74aa60e1e74e42a97de74022308aa6",
            "882e3749967b4a01b5adc43644eff21c",
            "1052e1e8b53041a89b6007c043f2156f",
            "a60e64504723498ab59aeab4be7d1b8f",
            "459f15005b8b4241acacf37eefc1d754",
            "1163f74797cc49ed90111408dbb90c9e",
            "553b5c0f7686493d9c98b4d9a1a2a3e9",
            "10959461f847483c9842f437a284045a",
            "ea2391891c7343d3b2fd63303900f38e",
            "27f1d23aa2ed41dbb709f3b38cdea491",
            "7ca595ec37444495a4a12d2ff0ba13fc",
            "93891bd2fd284c1d9d661635bc32d1f1",
            "64eb77d41aec46a294ed8745c18887a2",
            "315de6154471496d9752f7658935ca72",
            "58961398af8c4553b3ab354d06b7abf7",
            "780c3c47344246b08664d6ff9fcd576a",
            "1ac947535ffa468c95ef031476a4b17a",
            "47c9f200351e4b618f295d25a7e6cf76",
            "88561f7584db47b38d5908708603ad70",
            "a133cdaa86984f82b8a9c7239e206e6b",
            "543b92cf1a1347ec95f86babac098afc",
            "62330d03ae7d4b599e027f4e39b1c768",
            "5260a622843645d4a2260c1e32339be6",
            "1bb160d284d84e66834bfefabfddca15",
            "20cf06aa7aca4081ad3c0d70b26186de",
            "f5fccd1645b7413191776a5ca1a5387a",
            "5c4240abc55b42d4968ec92ced99c44f",
            "9338c962daff4c8e98901e20b56decf3",
            "2f418e5183bc432ab2173d7c7ece5142",
            "3b5d5175f3214571a348b8136944ca0e",
            "d3ed02ddbd954fd7bbef010da4ecc5f5",
            "d2b206c9143c4572b80550a7c6310ef3",
            "bb867dee78194b18be1a69f0b33142ad",
            "93247f2c469549e8b85a16993208e4fd",
            "47c0b22a6c714d778a82e42aa5bbee38",
            "8d1280a0052e44b3acd29bc6a6d239ab",
            "09fba238642d42f7939c6c16d9263122",
            "869c8a69af8d47bb9d9e72a1dcb85848",
            "dd488bb75cb144ac9aa81d2ad51d2337",
            "a40978fbdad94d97b2c416026d432397",
            "8ec99817c10141a79aa548210c5f1278",
            "73c188345b344bdaa2e088561836bd89",
            "112564e7f7764483881298b03e9b71d6",
            "c307834720e74076a3f35f78f2f5fdb5",
            "6eb5bdb0908a492f8b20e41caf114653",
            "fb52211a7a554466bf884f5cc7638109",
            "98d98e555c2342e49f5c0914eb8fd368",
            "474177bff7c84d9b922422eece018709",
            "6081c65813464180be4eb3ad82676352",
            "acc75db7f17a413887643b098b8c2f47",
            "74daaa849dc24d579a3c7852aa472fce",
            "1b5ed53f3444442ea9cad4f2d049bc8d",
            "41ac501359054c7c80e61b1a4e05cd61",
            "089bdd0ec58a489883b283fb908aaf97",
            "35412f18e7d7403abe0c717056c43e11",
            "169f3271a9954f348111c341040756bf"
          ]
        },
        "id": "aTh9ANv6kqXT",
        "outputId": "84abb24d-6f27-484d-bfb1-a84c0a50f082"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e61f896cb73452cb09fe3f3bff85fc8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f14879c9a05f424d9c9ef2d6c389e28d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/3.11M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "882e3749967b4a01b5adc43644eff21c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation-00000-of-00001.parquet:   0%|          | 0.00/72.8k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "64eb77d41aec46a294ed8745c18887a2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/148k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1bb160d284d84e66834bfefabfddca15",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/67349 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47c0b22a6c714d778a82e42aa5bbee38",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/872 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb52211a7a554466bf884f5cc7638109",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/1821 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Q2. Load the Dataset\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"glue\", \"sst2\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "lEcZ7oranvkr",
        "outputId": "274b3978-08cf-4818-dd03-e2df39ad794c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 67349,\n  \"fields\": [\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 66978,\n        \"samples\": [\n          \"mr. day-lewis roars with leonine power \",\n          \"a fairly slow paced , almost humdrum approach to character development \",\n          \"it 's not very interesting . \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"idx\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19442,\n        \"min\": 0,\n        \"max\": 67348,\n        \"num_unique_values\": 67349,\n        \"samples\": [\n          66730,\n          29890\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-206c2bd8-d1da-4d32-b3d9-faadb75744cc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "      <th>idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hide new secretions from the parental units</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>contains no wit , only labored gags</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>that loves its characters and communicates som...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>remains utterly satisfied to remain the same t...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>on the worst revenge-of-the-nerds clichÃ©s the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>that 's far too tragic to merit such superfici...</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>demonstrates that the director of such hollywo...</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>of saucy</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>a depressed fifteen-year-old 's suicidal poetry</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>are more deeply thought through than in most `...</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-206c2bd8-d1da-4d32-b3d9-faadb75744cc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-206c2bd8-d1da-4d32-b3d9-faadb75744cc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-206c2bd8-d1da-4d32-b3d9-faadb75744cc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-688bf6a4-72c6-4802-847a-30aabec7e912\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-688bf6a4-72c6-4802-847a-30aabec7e912')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-688bf6a4-72c6-4802-847a-30aabec7e912 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                            sentence  label  idx\n",
              "0       hide new secretions from the parental units       0    0\n",
              "1               contains no wit , only labored gags       0    1\n",
              "2  that loves its characters and communicates som...      1    2\n",
              "3  remains utterly satisfied to remain the same t...      0    3\n",
              "4  on the worst revenge-of-the-nerds clichÃ©s the ...      0    4\n",
              "5  that 's far too tragic to merit such superfici...      0    5\n",
              "6  demonstrates that the director of such hollywo...      1    6\n",
              "7                                          of saucy       1    7\n",
              "8   a depressed fifteen-year-old 's suicidal poetry       0    8\n",
              "9  are more deeply thought through than in most `...      1    9"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert to DataFrame to view\n",
        "df = pd.DataFrame(dataset['train'])\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165,
          "referenced_widgets": [
            "bbafcfca6a8d4e23b3ea253062cdf696",
            "b892eeb0117f4ab685c485fcc58a45f3",
            "1079f769395e4f2fb3b44a801a244713",
            "d8f423d3dbf0420eb0e394081b093683",
            "f747985419bd42ea8dd35d3c9b761730",
            "dea17b5131e44ded91f6eb780f603f9c",
            "8c6ee524b0794964916c649b596e3728",
            "bfb9264c39254c978ea403b89c328fd5",
            "ff9d765a7bb24a5a8d725d00ad7e9184",
            "51a5017a0e2044a8997414d373a1e7e4",
            "6bd23c2b51c04ae28e25471d8409a9bf",
            "8248919d9e544588a84102cc7cc5ca3a",
            "1711df6af93e4f9ebb979ad29530446b",
            "69d29f275ff64a4598ad89cb82841937",
            "261b71356d4740a886fcefac7a5e83b0",
            "4e54780af8c543d3bdd626e430b3faf5",
            "0996c89dbfc4434a9d36dbc3119a63ec",
            "ec68237e2c5b488eacff1e1a52c239c1",
            "56b9beeec6aa44b1a51637afeced307b",
            "10e45f6153034e0cbaa109779f22a00e",
            "9824336d87f942da94c0f23ef1eb7f85",
            "98cd468af3e3401ca4483f0d5ed450f5",
            "1c528dafb8c4444482605c5c7f68f5bd",
            "614526d6c959423899c91a930d9f1c60",
            "bafbadf9cc2b499d9e0f0e71b04b0567",
            "0b54f52755fc4c66a0573be0496fa81b",
            "8b32012bf81a4f0c9056bd766cae0af5",
            "dc3487a293344189b8d28436698faf77",
            "72b8e5fbd83c436dbe98cac5e61db884",
            "80e9f22d3996409bbd5575a98c89000c",
            "a0733dfda06141eeae83dfb8a0f8ef33",
            "c19c5c303a3d4ad298f400187d506153",
            "9106bc4a1c724890acc4fad6d5cf534d"
          ]
        },
        "id": "MXnH_lk9oLUC",
        "outputId": "c58f26fe-17d9-4c95-b8a7-97d5a9923228"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bbafcfca6a8d4e23b3ea253062cdf696",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/67349 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8248919d9e544588a84102cc7cc5ca3a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/872 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c528dafb8c4444482605c5c7f68f5bd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1821 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'sentence': Value(dtype='string', id=None),\n",
              " 'label': ClassLabel(names=['negative', 'positive'], id=None),\n",
              " 'idx': Value(dtype='int32', id=None)}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Q3. Preprocess the Data\n",
        "\n",
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    text = re.sub(r'\\s+', ' ', text)     # Remove extra whitespace\n",
        "    return text.strip()\n",
        "\n",
        "# Apply cleaning\n",
        "dataset = dataset.map(lambda x: {\"sentence\": clean_text(x[\"sentence\"])})\n",
        "\n",
        "# Check label distribution\n",
        "dataset['train'].features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKauo5QQo2Gq"
      },
      "source": [
        "**Q4. Importing Tokenizer and Model Class from Hugging Face**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQAi38GWoYjf"
      },
      "outputs": [],
      "source": [
        "# import tokenizer and model class from hugging face\n",
        "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ei0wc7kMp_v2",
        "outputId": "e8401942-12d6-4af1-ccb7-216abbdcceda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.52.4\n"
          ]
        }
      ],
      "source": [
        "import transformers\n",
        "print(transformers.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232,
          "referenced_widgets": [
            "e921a65b51154fd7ae41bce51dffe3de",
            "97dee4694d66401bbd5a0d9f36166064",
            "ed403bc57c034e3fb8e5518b5f91397d",
            "e3289f330da24af1abd50f489f659e9a",
            "da38e5ad8bd54296ab3eff13cf1e69aa",
            "d60fab770b30405c86be825827faa2c3",
            "872e01c72d04431d8d1ff516ec8d61ea",
            "480974f7987d4a2db2d5049caac48906",
            "9c578ce8b8244414a27a733ef331b88e",
            "d26466da8804469ca03ba5bd35a71da7",
            "505e98b862d547a3a131e2a471d7663b",
            "37a81fbf06bd4a47973b6d80488ef404",
            "2c577a75ddd649acaeeea83f151b1299",
            "8bad52e8ed2e4c71b8debd4f4efcef7c",
            "fa06b4d38e6a4487acc98ef694a8a1be",
            "639205b370f54f419dacf08ea644a705",
            "623aeff676e341f59ecb34f12a6e58aa",
            "893507f973dc4f5f8c40e72838fb91fd",
            "f9ac7d02cb2c4da1972c908050cafb51",
            "57c62cb703424c5ebfb02d7970589704",
            "b6bd3e3aa261495a81d28a880aa9a9ca",
            "261f7b6a8d5a4a8186ed780e36ef02ac",
            "b8df6be3f12d4107948ead181b4bb58b",
            "17fc1dd47b14460c9c24992e7979bfa5",
            "51830c7edd704a70877ebc6ba882e483",
            "4fd5ab9dc15e4afaa46ca2af8444f026",
            "2259cd0d6b934b7d9bcb40d7b52af044",
            "62782d5e0fe64c64862131736f065fc5",
            "840e8c44db1c4bd29b4f2dcabee060f7",
            "10dab3c0d704471ab476460a237e14d5",
            "1d7dfcbe6f634608a15236d2cbeefc90",
            "0d596689442947f48c49bc11ef3901b8",
            "7dc53271e6554ffab8abe59b052d46d9",
            "9eb00654d6c54455aa56de54bd509b4e",
            "771685b1fbc742999aefb69505727892",
            "9b1bf613ce5244d7be836df91d99d6f9",
            "0c3119d7b6e14276844b2e27b08a7cab",
            "fac60447b55b4d2b9217dbde94dd466d",
            "332437df10e24c618a23c9b8bdf61f0e",
            "e0bf53732b64427cb423a1655176cfff",
            "0645f62c9c4b47669981c2c64fbd3b0f",
            "e161af5f73cc40079ee2d8579366d3a5",
            "236631ea306e44dba3cae3ddd01dc0b2",
            "8f9bd0b381204cb99e543deb76300623",
            "fbd961ae760f414bbdd055f0fab88103",
            "0d2b34f513ad447fb08021e0839f8d37",
            "4e5a0011550841758c1cf63b0380b6c3",
            "b007260af5c74bc7a261711a5becbfb0",
            "4aa27645bb4b4f90acf67de566012b53",
            "68834e066e9f40e09515778cac0e1712",
            "a7e90be397ce46ae9ede9237d32c082d",
            "8ed9de99beaf44f9856137429a68d804",
            "e663245af6364cd98219459d1576213e",
            "90cdef7bdf5040eb929916e37d9fdc25",
            "ed6a4151b12d42e9ab9c34477da89b44"
          ]
        },
        "id": "Z5dax2Y5oP5e",
        "outputId": "ec969a82-4374-4beb-b82d-c470559e7966"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e921a65b51154fd7ae41bce51dffe3de",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37a81fbf06bd4a47973b6d80488ef404",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b8df6be3f12d4107948ead181b4bb58b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9eb00654d6c54455aa56de54bd509b4e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fbd961ae760f414bbdd055f0fab88103",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Q4. Load Pre-trained \"distilbert\" Model and Tokenizer\n",
        "\n",
        "model_name = \"distilbert-base-uncased\" # pre trained model\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name) # loading the corresponding tokenizer\n",
        "model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=2) # loading the classification model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "16959b0548fb4b93a29a8507d353c628",
            "ba322d7879b04699a1b1cf6ce28e8c84",
            "80b6091d84d24235bf9e8393c55b0fb4",
            "3477f1e5e18f429ea8ef4a2187107097",
            "65b35fc1d5a94b52ab7a533271d11848",
            "bb0f0fc2acdf40ac8ede1e4cc288264f",
            "70e395fc01dc4cbbad7d82920d186092",
            "12830812464e455fa86190edd31310e9",
            "8551788f44994752b94b6b0cfca18212",
            "3c178d38fb384b3aa70c47663bfe72e2",
            "5c3958793e244355b1426683e68c7c70",
            "147d9af2f70245b186accffcbbdffbda",
            "70170bfe141c4366a39129d478560659",
            "8cd48359edda448ba1abbd890ee6785b",
            "c48e9e3e102a4f58b47fcaa22d9a1278",
            "6892806fc42141de98b17c736794d406",
            "cdedca1045814798a4dba6714949bd1e",
            "ea08f21a5a2a45be8f09f62ef7e0e5dd",
            "9aa3d1cd26d0442fbe531d83c39171a4",
            "92a22fd2081340559240d8859af28de7",
            "c6b56dd401944b09a49cb7e76b56c709",
            "31ac460669e84d7182621f2bd4bbe961",
            "7245d36c44cf4f018fbbd1bcc8ef06ba",
            "0a216ba1f7cb4be5aab8e68a92e29e19",
            "8b523687df634c7b84649335aaea010c",
            "1b2cce0457b9432292264644eac295de",
            "a71d1ea480034d50a075625d27a94642",
            "4fdfcfc3dede481daf4160ae4d70f0a5",
            "b99c6b58fe1945ca92b8136ebebebf82",
            "04934e16aca34dfb87132276c4efc19f",
            "ebca4f6358e448fb8de760a354284150",
            "e4d2f76b06c84f0180abb713a80f9b9b",
            "0df4b2b821f248dbb7c291ec80dd11cb"
          ]
        },
        "id": "7u1RsW5ApoT6",
        "outputId": "42bf21f2-2f67-4227-f814-7415584a9439"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "16959b0548fb4b93a29a8507d353c628",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/67349 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "147d9af2f70245b186accffcbbdffbda",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/872 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7245d36c44cf4f018fbbd1bcc8ef06ba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1821 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Q5. Tokenize the Dataset\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"sentence\"], truncation=True, padding=\"max_length\", max_length=128)\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Set format for PyTorch\n",
        "tokenized_dataset.set_format(\"torch\", columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "# Split data\n",
        "train_dataset = tokenized_dataset[\"train\"]\n",
        "val_dataset = tokenized_dataset[\"validation\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnRZj6cYqYTR"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "GWHR5NOXp51b",
        "outputId": "54e3f4f9-a0ee-4bf8-f704-c2f6abc3cd4c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1827' max='4210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1827/4210 5:12:34 < 6:48:08, 0.10 it/s, Epoch 0.43/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.311400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.289900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.245300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3373' max='4210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3373/4210 9:34:48 < 2:22:43, 0.10 it/s, Epoch 0.80/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.311400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.289900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.245300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.236300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.219800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.225300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Q6. Fine-Tune the Model\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=64,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return {\"accuracy\": accuracy_score(labels, predictions)}\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0ItIsQGO8bm"
      },
      "outputs": [],
      "source": [
        "# Q7. Evaluate the Model\n",
        "\n",
        "# Evaluate on validation data\n",
        "results = trainer.evaluate()\n",
        "print(\"Validation Accuracy:\", results[\"eval_accuracy\"])\n",
        "\n",
        "# Classification Report\n",
        "predictions = trainer.predict(val_dataset)\n",
        "y_pred = np.argmax(predictions.predictions, axis=1)\n",
        "y_true = predictions.label_ids\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=[\"Negative\", \"Positive\"]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8a1CvqYqVE14"
      },
      "outputs": [],
      "source": [
        "# Q8. Visualize the Results\n",
        "\n",
        "training_logs = trainer.state.log_history\n",
        "\n",
        "train_loss = [log['loss'] for log in training_logs if 'loss' in log]\n",
        "eval_loss = [log['eval_loss'] for log in training_logs if 'eval_loss' in log]\n",
        "\n",
        "plt.plot(train_loss, label='Training Loss')\n",
        "plt.plot(eval_loss, label='Validation Loss')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss Curve\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_25Bt4VVSuo"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Negative\", \"Positive\"], yticklabels=[\"Negative\", \"Positive\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpoIOTT_YbEY"
      },
      "source": [
        "# **Predict the Sentiment of New text**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYLgrKVzYkOk"
      },
      "outputs": [],
      "source": [
        "def predict_sentiment(text, model, tokenizer):\n",
        "    # Tokenize and move to the same device as model\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128).to(model.device)\n",
        "\n",
        "    # Disable gradient calculation (faster, less memory)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits\n",
        "\n",
        "    # Get predicted class (0 or 1)\n",
        "    predicted_class_id = logits.argmax().item()\n",
        "\n",
        "    # Map to label name\n",
        "    label = model.config.id2label[predicted_class_id]\n",
        "\n",
        "    print(f\"Sentiment of \\\"{text}\\\" is: {label}\")\n",
        "    return label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntnDfCeYSHNf",
        "outputId": "a451149a-99b1-4ea9-a6ff-57ee0ed413b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ§  Best Model in Terms of Accuracy:\n",
            "âœ… roberta-base achieved the highest accuracy (93%) on the SST-2 sentiment classification task.\n",
            "\n",
            "âš¡ Best Model in Terms of Speed:\n",
            "âœ… distilbert-base-uncased was the fastest to train (in 12 hours) with decent accuracy (91%).\n",
            "\n",
            "ğŸ’¡ Conclusion:\n",
            "ğŸ”¸ Use roberta-base if you need top accuracy and donâ€™t mind longer training.\n",
            "ğŸ”¸ Use distilbert-base-uncased if you want a fast and lightweight model with good results.\n"
          ]
        }
      ],
      "source": [
        "# Q 10. Comparison of Model Performance\n",
        "\n",
        "print(\"ğŸ§  Best Model in Terms of Accuracy:\")\n",
        "print(\"âœ… roberta-base achieved the highest accuracy (93%) on the SST-2 sentiment classification task.\\n\")\n",
        "\n",
        "print(\"âš¡ Best Model in Terms of Speed:\")\n",
        "print(\"âœ… distilbert-base-uncased was the fastest to train (in 12 hours) with decent accuracy (91%).\\n\")\n",
        "\n",
        "print(\"ğŸ’¡ Conclusion:\")\n",
        "print(\"ğŸ”¸ Use roberta-base if you need top accuracy and donâ€™t mind longer training.\")\n",
        "print(\"ğŸ”¸ Use distilbert-base-uncased if you want a fast and lightweight model with good results.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}